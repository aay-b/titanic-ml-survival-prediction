# titanic-ml-survival-prediction
Predicting survival on the Titanic using machine learning for the classic Kaggle competition. Includes data cleaning, feature engineering, and model building with scikit-learn. Achieved strong accuracy with interpretable models on a binary classification task.



# ðŸš¢ Titanic ML Survival Prediction

This project solves the classic [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic) Kaggle competition using basic machine learning techniques.


## ðŸ“Œ Objective
Predict whether a passenger survived the Titanic shipwreck using features such as age, gender, class, fare, and more. This is a binary classification problem where the target variable is `Survived` (0 = No, 1 = Yes).

---

## What I Did
- Explored and cleaned the dataset
- Performed feature engineering (e.g., title extraction, family size)
- Handled missing data
- Applied models: Random Forest
- Evaluated model performance and tuned hyperparameters
- Submitted predictions to Kaggle for scoring

---

## Tools Used
- Python
- Pandas, NumPy
- Scikit-learn
- Matplotlib & Seaborn (for visualization)
- Jupyter Notebook / Kaggle Notebook

---

## Result
Achieved 77.5% Accuracy on the Kaggle leaderboard with this simple, interpretable model.

---

## ðŸ”— Kaggle Notebook

[ðŸ‘‰ View the Kaggle notebook here](https://www.kaggle.com/code/aayb10/titanic-77-5-accuracy-with-rfc-fe)
